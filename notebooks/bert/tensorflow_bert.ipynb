{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZiFclot_fAXR"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import bert\n",
        "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "from tensorflow.keras.models import Model       # Keras is the new high level API for TensorFlow\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NhH5ACDt5nfR"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "final_model = keras.models.load_model('baseline_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_3koe1J-fCUE"
      },
      "outputs": [],
      "source": [
        "max_seq_length = 128  # Your choice here.\n",
        "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                       name=\"input_word_ids\")\n",
        "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                   name=\"input_mask\")\n",
        "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                    name=\"segment_ids\")\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=True)\n",
        "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "\n",
        "model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=[pooled_output, sequence_output])\n",
        "\n",
        "# See BERT paper: https://arxiv.org/pdf/1810.04805.pdf\n",
        "# And BERT implementation convert_single_example() at https://github.com/google-research/bert/blob/master/run_classifier.py\n",
        "\n",
        "def get_masks(tokens, max_seq_length):\n",
        "    \"\"\"Mask for padding\"\"\"\n",
        "    if len(tokens)>max_seq_length:\n",
        "        raise IndexError(\"Token length more than max seq length!\")\n",
        "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "\n",
        "def get_segments(tokens, max_seq_length):\n",
        "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
        "    if len(tokens)>max_seq_length:\n",
        "        raise IndexError(\"Token length more than max seq length!\")\n",
        "    segments = []\n",
        "    current_segment_id = 0\n",
        "    for token in tokens:\n",
        "        segments.append(current_segment_id)\n",
        "        if token == \"[SEP]\":\n",
        "            current_segment_id = 1\n",
        "    return segments + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "\n",
        "def get_ids(tokens, tokenizer, max_seq_length):\n",
        "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
        "    return input_ids\n",
        "\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Oa3HGAHJfDy-",
        "outputId": "25c2784b-474a-42d5-db01-871904c1f7a4"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model_1\" expects 3 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 1, 128) dtype=int32>]\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m input_masks \u001b[39m=\u001b[39m get_masks(stokens, max_seq_length)\n\u001b[0;32m      9\u001b[0m input_segments \u001b[39m=\u001b[39m get_segments(stokens, max_seq_length)\n\u001b[1;32m---> 11\u001b[0m pool_embs, all_embs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit([[input_ids],[input_masks],[input_segments]])\n\u001b[0;32m     13\u001b[0m \u001b[39mprint\u001b[39m(pool_embs\u001b[39m.\u001b[39mshape)\n",
            "File \u001b[1;32mc:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file1w78veqb.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model_1\" expects 3 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 1, 128) dtype=int32>]\n"
          ]
        }
      ],
      "source": [
        "s = \"I want to die. I want to die. I want to die.\"\n",
        "\n",
        "stokens = tokenizer.tokenize(s)\n",
        "\n",
        "stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
        "\n",
        "input_ids = get_ids(stokens, tokenizer, max_seq_length)\n",
        "input_masks = get_masks(stokens, max_seq_length)\n",
        "input_segments = get_segments(stokens, max_seq_length)\n",
        "\n",
        "pool_embs, all_embs = model.fit([[input_ids],[input_masks],[input_segments]])\n",
        "\n",
        "print(pool_embs.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "UEDxDsNMih8W",
        "outputId": "a148e2bc-afd3-427a-91d1-b4fcc3525ed2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pool_embs' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions \u001b[39m=\u001b[39m final_model\u001b[39m.\u001b[39mpredict(pool_embs)\n\u001b[0;32m      3\u001b[0m a_number \u001b[39m=\u001b[39m predictions[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m      4\u001b[0m significant_digits \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'pool_embs' is not defined"
          ]
        }
      ],
      "source": [
        "predictions = final_model.predict(pool_embs)\n",
        "\n",
        "a_number = predictions[0][0]\n",
        "significant_digits = 3\n",
        "rounded_number =  round(a_number, significant_digits - int(math.floor(math.log10(abs(a_number)))) - 1)\n",
        "\n",
        "print(rounded_number)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "tensorflow-bert.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
