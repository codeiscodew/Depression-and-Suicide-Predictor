{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayaanzhaque/SuiSense/blob/master/notebooks/bert/tensorflow_bert_before.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JRSdcSfXe1FG",
        "outputId": "ffd53b50-35fd-4732-96d0-da188c0ebd54"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement tensorflow==2.0 (from versions: 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0)\n",
            "ERROR: No matching distribution found for tensorflow==2.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_hub in c:\\users\\91897\\desktop\\suicide-prediction-app\\ayushi\\lib\\site-packages (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\91897\\desktop\\suicide-prediction-app\\ayushi\\lib\\site-packages (from tensorflow_hub) (4.22.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\91897\\desktop\\suicide-prediction-app\\ayushi\\lib\\site-packages (from tensorflow_hub) (1.23.5)\n",
            "Requirement already satisfied: bert-for-tf2 in c:\\users\\91897\\desktop\\suicide-prediction-app\\ayushi\\lib\\site-packages (0.14.9)\n",
            "Requirement already satisfied: params-flow>=0.8.0 in c:\\users\\91897\\desktop\\suicide-prediction-app\\ayushi\\lib\\site-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied: py-params>=0.9.6 in c:\\users\\91897\\desktop\\suicide-prediction-app\\ayushi\\lib\\site-packages (from bert-for-tf2) (0.10.2)\n",
            "Requirement already satisfied: tqdm in c:\\users\\91897\\desktop\\suicide-prediction-app\\ayushi\\lib\\site-packages (from params-flow>=0.8.0->bert-for-tf2) (4.65.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\91897\\desktop\\suicide-prediction-app\\ayushi\\lib\\site-packages (from params-flow>=0.8.0->bert-for-tf2) (1.23.5)\n",
            "Requirement already satisfied: colorama in c:\\users\\91897\\desktop\\suicide-prediction-app\\ayushi\\lib\\site-packages (from tqdm->params-flow>=0.8.0->bert-for-tf2) (0.4.6)\n",
            "Requirement already satisfied: sentencepiece in c:\\users\\91897\\desktop\\suicide-prediction-app\\ayushi\\lib\\site-packages (0.1.98)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.0\n",
        "!pip install tensorflow_hub\n",
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZiFclot_fAXR"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import bert\n",
        "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "from tensorflow.keras.models import Model       # Keras is the new high level API for TensorFlow\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NhH5ACDt5nfR"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "final_model = keras.models.load_model('baseline_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_3koe1J-fCUE"
      },
      "outputs": [],
      "source": [
        "max_seq_length = 512  # Your choice here.\n",
        "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                       name=\"input_word_ids\")\n",
        "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                   name=\"input_mask\")\n",
        "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                    name=\"segment_ids\")\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=True)\n",
        "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "\n",
        "model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=[pooled_output, sequence_output])\n",
        "\n",
        "# See BERT paper: https://arxiv.org/pdf/1810.04805.pdf\n",
        "# And BERT implementation convert_single_example() at https://github.com/google-research/bert/blob/master/run_classifier.py\n",
        "\n",
        "def get_masks(tokens, max_seq_length):\n",
        "    \"\"\"Mask for padding\"\"\"\n",
        "    if len(tokens)>max_seq_length:\n",
        "        raise IndexError(\"Token length more than max seq length!\")\n",
        "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "\n",
        "def get_segments(tokens, max_seq_length):\n",
        "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
        "    if len(tokens)>max_seq_length:\n",
        "        raise IndexError(\"Token length more than max seq length!\")\n",
        "    segments = []\n",
        "    current_segment_id = 0\n",
        "    for token in tokens:\n",
        "        segments.append(current_segment_id)\n",
        "        if token == \"[SEP]\":\n",
        "            current_segment_id = 1\n",
        "    return segments + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "\n",
        "def get_ids(tokens, tokenizer, max_seq_length):\n",
        "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
        "    return input_ids\n",
        "\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Oa3HGAHJfDy-",
        "outputId": "8c3d0eb6-8819-4358-d9b0-4c82c2ec90f0"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model\" expects 3 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 1, 512) dtype=int32>]\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m input_masks \u001b[39m=\u001b[39m get_masks(stokens, max_seq_length)\n\u001b[0;32m      9\u001b[0m input_segments \u001b[39m=\u001b[39m get_segments(stokens, max_seq_length)\n\u001b[1;32m---> 11\u001b[0m pool_embs, all_embs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict([[input_ids],[input_masks],[input_segments]])\n\u001b[0;32m     14\u001b[0m \u001b[39mprint\u001b[39m(pool_embs\u001b[39m.\u001b[39mshape)\n",
            "File \u001b[1;32mc:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filez68wkj4l.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\91897\\Desktop\\Suicide-Prediction-App\\ayushi\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model\" expects 3 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 1, 512) dtype=int32>]\n"
          ]
        }
      ],
      "source": [
        "s = \"I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die I want to die\"\n",
        "\n",
        "stokens = tokenizer.tokenize(s)\n",
        "\n",
        "stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
        "\n",
        "input_ids = get_ids(stokens, tokenizer, max_seq_length)\n",
        "input_masks = get_masks(stokens, max_seq_length)\n",
        "input_segments = get_segments(stokens, max_seq_length)\n",
        "\n",
        "pool_embs, all_embs = model.predict([[input_ids],[input_masks],[input_segments]])\n",
        "\n",
        "\n",
        "print(pool_embs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "UEDxDsNMih8W",
        "outputId": "798772c4-ba7f-42e8-9d65-dee6866a453d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.5506451]]\n"
          ]
        }
      ],
      "source": [
        "predictions = final_model.predict(pool_embs)\n",
        "print(predictions)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "tensorflow-bert-before.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
